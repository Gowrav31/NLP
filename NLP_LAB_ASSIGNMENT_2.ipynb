{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzIzRHwXMHqFQhHjx/URMN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gowrav31/NLP/blob/main/NLP_LAB_ASSIGNMENT_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csDXVwO4hobV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecb7b521"
      },
      "source": [
        "**Reasoning**:\n",
        "Install the required libraries, `nltk` and `spaCy`, using pip.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dcf3a95",
        "outputId": "5bb76fe8-c5dd-4be9-96eb-aceef7e813b6"
      },
      "source": [
        "pip install nltk spacy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.11)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.20.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.12.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.11.12)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45b584c5",
        "outputId": "bad5e5bd-d309-4342-ada7-739360910fee"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebc7679d",
        "outputId": "7cb8ae47-c985-4d06-b2f7-3f024baf3b27"
      },
      "source": [
        "import spacy\n",
        "# Download the 'en_core_web_sm' spaCy model\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/12.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/12.8 MB\u001b[0m \u001b[31m153.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m11.9/12.8 MB\u001b[0m \u001b[31m186.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m185.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m104.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e6bb641",
        "outputId": "48acc117-d0ee-47fd-f22b-cd197d40029c"
      },
      "source": [
        "medical_text = \"The patient presented with chronic inflammation and experiencing severe pain in the abdominal area. Physicians are investigating potential diagnoses of gastritis or colitis.\"\n",
        "print(\"Sample Medical Text:\\n\", medical_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Medical Text:\n",
            " The patient presented with chronic inflammation and experiencing severe pain in the abdominal area. Physicians are investigating potential diagnoses of gastritis or colitis.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90bee33f",
        "outputId": "f8cb1223-62eb-4e4b-ef3b-78211c952fac"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "\n",
        "# 2. Apply sentence tokenization\n",
        "sentences = sent_tokenize(medical_text)\n",
        "print(\"NLTK Sentence Tokenization:\", sentences)\n",
        "\n",
        "# 3. For each sentence, apply word tokenization and flatten\n",
        "words_nested = [word_tokenize(sentence) for sentence in sentences]\n",
        "nltk_words = [word for sublist in words_nested for word in sublist]\n",
        "print(\"\\nNLTK Word Tokenization:\", nltk_words)\n",
        "\n",
        "# 5. Import PorterStemmer and create an instance\n",
        "stemmer = PorterStemmer()\n",
        "# 6. Apply stemming\n",
        "nltk_stemmed_words = [stemmer.stem(word) for word in nltk_words]\n",
        "print(\"\\nNLTK Stemmed Words:\", nltk_stemmed_words)\n",
        "\n",
        "# 7. Import WordNetLemmatizer and create an instance\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "# 8. Apply lemmatization\n",
        "nltk_lemmatized_words = [lemmatizer.lemmatize(word) for word in nltk_words]\n",
        "print(\"\\nNLTK Lemmatized Words:\", nltk_lemmatized_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK Sentence Tokenization: ['The patient presented with chronic inflammation and experiencing severe pain in the abdominal area.', 'Physicians are investigating potential diagnoses of gastritis or colitis.']\n",
            "\n",
            "NLTK Word Tokenization: ['The', 'patient', 'presented', 'with', 'chronic', 'inflammation', 'and', 'experiencing', 'severe', 'pain', 'in', 'the', 'abdominal', 'area', '.', 'Physicians', 'are', 'investigating', 'potential', 'diagnoses', 'of', 'gastritis', 'or', 'colitis', '.']\n",
            "\n",
            "NLTK Stemmed Words: ['the', 'patient', 'present', 'with', 'chronic', 'inflamm', 'and', 'experienc', 'sever', 'pain', 'in', 'the', 'abdomin', 'area', '.', 'physician', 'are', 'investig', 'potenti', 'diagnos', 'of', 'gastriti', 'or', 'coliti', '.']\n",
            "\n",
            "NLTK Lemmatized Words: ['The', 'patient', 'presented', 'with', 'chronic', 'inflammation', 'and', 'experiencing', 'severe', 'pain', 'in', 'the', 'abdominal', 'area', '.', 'Physicians', 'are', 'investigating', 'potential', 'diagnosis', 'of', 'gastritis', 'or', 'colitis', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcce3351",
        "outputId": "ca28ddcc-7141-45ef-b483-05cae0ac1b8e"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "print(\"Downloaded 'punkt_tab' NLTK resource.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded 'punkt_tab' NLTK resource.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59497185",
        "outputId": "85036a40-e435-4f73-c55b-bf7b1d725055"
      },
      "source": [
        "import spacy\n",
        "\n",
        "# 1. Load the en_core_web_sm spaCy model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# 2. Process the medical_text\n",
        "doc = nlp(medical_text)\n",
        "\n",
        "# 3. Extract word tokens\n",
        "spacy_words = [token.text for token in doc]\n",
        "print(\"\\nspaCy Word Tokenization:\", spacy_words)\n",
        "\n",
        "# 4. Extract sentences\n",
        "spacy_sentences = [sent.text for sent in doc.sents]\n",
        "print(\"\\nspaCy Sentence Tokenization:\", spacy_sentences)\n",
        "\n",
        "# 5. Extract lemmas\n",
        "spacy_lemmas = [token.lemma_ for token in doc]\n",
        "print(\"\\nspaCy Lemmatized Words:\", spacy_lemmas)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "spaCy Word Tokenization: ['The', 'patient', 'presented', 'with', 'chronic', 'inflammation', 'and', 'experiencing', 'severe', 'pain', 'in', 'the', 'abdominal', 'area', '.', 'Physicians', 'are', 'investigating', 'potential', 'diagnoses', 'of', 'gastritis', 'or', 'colitis', '.']\n",
            "\n",
            "spaCy Sentence Tokenization: ['The patient presented with chronic inflammation and experiencing severe pain in the abdominal area.', 'Physicians are investigating potential diagnoses of gastritis or colitis.']\n",
            "\n",
            "spaCy Lemmatized Words: ['the', 'patient', 'present', 'with', 'chronic', 'inflammation', 'and', 'experience', 'severe', 'pain', 'in', 'the', 'abdominal', 'area', '.', 'Physicians', 'be', 'investigate', 'potential', 'diagnosis', 'of', 'gastritis', 'or', 'colitis', '.']\n"
          ]
        }
      ]
    }
  ]
}